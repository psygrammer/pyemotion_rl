{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "my_dqn_pytorch.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyO7h0N4dORAsC6D3s36RbNg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mooithub/pyemotion_rl/blob/master/my_examples/kms_examples/DeepRLBook/Chapter06/my_dqn_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6A_BQA4WFdH"
      },
      "source": [
        "# DQN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oU3U9mhpT2Wm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2834f130-3d76-4216-c11b-a101c0f1da8d"
      },
      "source": [
        "!git clone https://github.com/psygrammer/pyemotion_rl.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'pyemotion_rl'...\n",
            "remote: Enumerating objects: 336, done.\u001b[K\n",
            "remote: Counting objects: 100% (336/336), done.\u001b[K\n",
            "remote: Compressing objects: 100% (265/265), done.\u001b[K\n",
            "remote: Total 336 (delta 125), reused 132 (delta 26), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (336/336), 16.59 MiB | 6.62 MiB/s, done.\n",
            "Resolving deltas: 100% (125/125), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRhMACBAeC7x"
      },
      "source": [
        "import cv2\n",
        "import gym\n",
        "import gym.spaces\n",
        "import numpy as np\n",
        "import collections\n",
        "\n",
        "\n",
        "class FireResetEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None):\n",
        "        \"\"\"For environments where the user need to press FIRE for the game to start.\"\"\"\n",
        "        super(FireResetEnv, self).__init__(env)\n",
        "        assert env.unwrapped.get_action_meanings()[1] == 'FIRE'\n",
        "        assert len(env.unwrapped.get_action_meanings()) >= 3\n",
        "\n",
        "    def step(self, action):\n",
        "        return self.env.step(action)\n",
        "\n",
        "    def reset(self):\n",
        "        self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(1)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        obs, _, done, _ = self.env.step(2)\n",
        "        if done:\n",
        "            self.env.reset()\n",
        "        return obs\n",
        "\n",
        "\n",
        "class MaxAndSkipEnv(gym.Wrapper):\n",
        "    def __init__(self, env=None, skip=4):\n",
        "        \"\"\"Return only every `skip`-th frame\"\"\"\n",
        "        super(MaxAndSkipEnv, self).__init__(env)\n",
        "        # most recent raw observations (for max pooling across time steps)\n",
        "        self._obs_buffer = collections.deque(maxlen=2)\n",
        "        self._skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = None\n",
        "        for _ in range(self._skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            self._obs_buffer.append(obs)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        max_frame = np.max(np.stack(self._obs_buffer), axis=0)\n",
        "        return max_frame, total_reward, done, info\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"Clear past frame buffer and init. to first obs. from inner env.\"\"\"\n",
        "        self._obs_buffer.clear()\n",
        "        obs = self.env.reset()\n",
        "        self._obs_buffer.append(obs)\n",
        "        return obs\n",
        "\n",
        "\n",
        "class ProcessFrame84(gym.ObservationWrapper):\n",
        "    def __init__(self, env=None):\n",
        "        super(ProcessFrame84, self).__init__(env)\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0, high=255, shape=(84, 84, 1), dtype=np.uint8)\n",
        "\n",
        "    def observation(self, obs):\n",
        "        return ProcessFrame84.process(obs)\n",
        "\n",
        "    @staticmethod\n",
        "    def process(frame):\n",
        "        if frame.size == 210 * 160 * 3:\n",
        "            img = np.reshape(frame, [210, 160, 3]).astype(\n",
        "                np.float32)\n",
        "        elif frame.size == 250 * 160 * 3:\n",
        "            img = np.reshape(frame, [250, 160, 3]).astype(\n",
        "                np.float32)\n",
        "        else:\n",
        "            assert False, \"Unknown resolution.\"\n",
        "        img = img[:, :, 0] * 0.299 + img[:, :, 1] * 0.587 + \\\n",
        "              img[:, :, 2] * 0.114\n",
        "        resized_screen = cv2.resize(\n",
        "            img, (84, 110), interpolation=cv2.INTER_AREA)\n",
        "        x_t = resized_screen[18:102, :]\n",
        "        x_t = np.reshape(x_t, [84, 84, 1])\n",
        "        return x_t.astype(np.uint8)\n",
        "\n",
        "\n",
        "class ImageToPyTorch(gym.ObservationWrapper):\n",
        "    def __init__(self, env):\n",
        "        super(ImageToPyTorch, self).__init__(env)\n",
        "        old_shape = self.observation_space.shape\n",
        "        new_shape = (old_shape[-1], old_shape[0], old_shape[1])\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            low=0.0, high=1.0, shape=new_shape, dtype=np.float32)\n",
        "\n",
        "    def observation(self, observation):\n",
        "        return np.moveaxis(observation, 2, 0)\n",
        "\n",
        "\n",
        "class ScaledFloatFrame(gym.ObservationWrapper):\n",
        "    def observation(self, obs):\n",
        "        return np.array(obs).astype(np.float32) / 255.0\n",
        "\n",
        "\n",
        "class BufferWrapper(gym.ObservationWrapper):\n",
        "    def __init__(self, env, n_steps, dtype=np.float32):\n",
        "        super(BufferWrapper, self).__init__(env)\n",
        "        self.dtype = dtype\n",
        "        old_space = env.observation_space\n",
        "        self.observation_space = gym.spaces.Box(\n",
        "            old_space.low.repeat(n_steps, axis=0),\n",
        "            old_space.high.repeat(n_steps, axis=0), dtype=dtype)\n",
        "\n",
        "    def reset(self):\n",
        "        self.buffer = np.zeros_like(\n",
        "            self.observation_space.low, dtype=self.dtype)\n",
        "        return self.observation(self.env.reset())\n",
        "\n",
        "    def observation(self, observation):\n",
        "        self.buffer[:-1] = self.buffer[1:]\n",
        "        self.buffer[-1] = observation\n",
        "        return self.buffer\n",
        "\n",
        "\n",
        "def make_env(env_name):\n",
        "    env = gym.make(env_name)\n",
        "    env = MaxAndSkipEnv(env)\n",
        "    env = FireResetEnv(env)\n",
        "    env = ProcessFrame84(env)\n",
        "    env = ImageToPyTorch(env)\n",
        "    env = BufferWrapper(env, 4)\n",
        "    return ScaledFloatFrame(env)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5zCdPCx-XLju"
      },
      "source": [
        "class DQN:\n",
        "  def __init__(self):\n",
        "    pass\n",
        "\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5IISk77WSif"
      },
      "source": [
        "net = DQN()"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVqrswPeXK0x"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pyn3nR_BWlml"
      },
      "source": [
        "class Agent:\n",
        "  def __init__(self, env):\n",
        "    self.env = env\n",
        "\n",
        "  def play_step(self, net, epsilon, device):\n",
        "    reward = 0\n",
        "    print(\"action:\")\n",
        "    action = self.env.action_space.sample()\n",
        "    print(action)\n",
        "    print(\"obs:\")\n",
        "    obs = self.env.observation_space.sample()\n",
        "    print(obs)\n",
        "\n",
        "    return reward\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyaZS67gdFuA"
      },
      "source": [
        "env = make_env(\"PongNoFrameskip-v4\")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B-FJQZGWjhz"
      },
      "source": [
        "agent = Agent(env)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WoTj55TXSIl"
      },
      "source": [
        "epsilon=0\n",
        "device=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zcEXXjbjcY84"
      },
      "source": [
        "reward = 0\n",
        "epsilon = 0\n",
        "device = 0"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dqi6lL2_WgPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4674dc7d-05f2-4a90-b248-a9f71f613e88"
      },
      "source": [
        "reward += agent.play_step(net, epsilon, device=device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "action:\n",
            "0\n",
            "obs:\n",
            "[[[0.7812051  0.46217105 0.8005907  ... 0.97476923 0.32244882 0.8649571 ]\n",
            "  [0.03037664 0.83315784 0.7733953  ... 0.40451014 0.94008327 0.22292797]\n",
            "  [0.5756634  0.8324113  0.8930624  ... 0.32795784 0.6076059  0.76291233]\n",
            "  ...\n",
            "  [0.5160297  0.7955999  0.18357807 ... 0.09747858 0.9735003  0.4396744 ]\n",
            "  [0.49294585 0.2666546  0.10881287 ... 0.62490076 0.3491353  0.9185548 ]\n",
            "  [0.33584905 0.374239   0.72649926 ... 0.89930695 0.61525065 0.84411216]]\n",
            "\n",
            " [[0.66039854 0.0204379  0.64591    ... 0.9523724  0.32150406 0.71167195]\n",
            "  [0.81265    0.53409725 0.74865955 ... 0.938989   0.63491154 0.5634564 ]\n",
            "  [0.5699733  0.16118458 0.8824068  ... 0.29843187 0.14388335 0.39418966]\n",
            "  ...\n",
            "  [0.75718826 0.06654327 0.07573684 ... 0.9610781  0.6548166  0.328281  ]\n",
            "  [0.6346106  0.97894937 0.18874396 ... 0.60629845 0.7081806  0.46559456]\n",
            "  [0.57174975 0.80954623 0.25579658 ... 0.78857106 0.34897763 0.128554  ]]\n",
            "\n",
            " [[0.6346261  0.34278873 0.11005142 ... 0.8135684  0.9158217  0.57338256]\n",
            "  [0.4647707  0.18897972 0.7815848  ... 0.739026   0.06947614 0.7058496 ]\n",
            "  [0.8533157  0.34081003 0.06397889 ... 0.9577119  0.96956867 0.77625126]\n",
            "  ...\n",
            "  [0.42770943 0.34488097 0.98570526 ... 0.46527946 0.03720233 0.15496291]\n",
            "  [0.35665396 0.35968548 0.28210375 ... 0.2427417  0.674737   0.8756222 ]\n",
            "  [0.42621884 0.6010753  0.94795656 ... 0.24750279 0.22927062 0.3091066 ]]\n",
            "\n",
            " [[0.873149   0.53260094 0.7302991  ... 0.07683068 0.0043643  0.20958486]\n",
            "  [0.98311853 0.19545145 0.6266358  ... 0.7882343  0.76235735 0.8373034 ]\n",
            "  [0.76534927 0.4806085  0.62478    ... 0.9125353  0.82689613 0.08127975]\n",
            "  ...\n",
            "  [0.50674003 0.94005716 0.5582755  ... 0.29919127 0.8595539  0.7449082 ]\n",
            "  [0.8946323  0.11028332 0.9229352  ... 0.13450813 0.37112254 0.7687953 ]\n",
            "  [0.4363699  0.52753687 0.9320755  ... 0.07711677 0.9113442  0.69103986]]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBloegoaWhpu",
        "outputId": "a898fb92-1c46-4c70-f578-9ed966fc1a1a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "reward"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTV2y0Kacbyg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}